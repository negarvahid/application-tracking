{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated CV <-> Job Description Ranker "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task** :  This unsupervised machine learning algorithm finds the top fit for a certain job description using Topic Modeling and Cosine Similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset** : around 145,000 job descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Modules\n",
    "### 2. Preprocessing\n",
    "### 3. TF-IDF VS BOW \n",
    "### 4. Topic Modeling\n",
    "### 5. Cosine Similarity\n",
    "### 6. Test\n",
    "### 7. Possible Updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import corpus\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from pprint import pprint\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balancing out the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing all unecessery characters and numbers from our text and removed stop words, stemmed and lemmantized our corpus for better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd2 = pd.read_csv('all_jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18180, 11495, 11571, 7069, 13251]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choosing 300000random job descriptions\n",
    "import random\n",
    "random.seed(333)\n",
    "indices = jd2.index.values.tolist()\n",
    "\n",
    "random_30000 = random.sample(indices, 20000)\n",
    "\n",
    "random_30000[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the random 10000 of second dataset\n",
    "jd2_train = jd2.loc[random_10000, :]\n",
    "jd2_train = jd2_train.reset_index(drop = True)\n",
    "jd2_train = jd2_train['Job Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd3 = pd.read_csv('dice_com-job_us_sample.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd3_train = jd3['jobdescription']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatinating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd2_train = jd2_train.append(jd3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd2_train = jd2_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = jd2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all urls\n",
    "def remove_urls(s):\n",
    "    s = re.sub('[^\\s]*.com[^\\s]*', \"\", s)\n",
    "    s = re.sub('[^\\s]*www.[^\\s]*', \"\", s)\n",
    "    s = re.sub('[^\\s]*.co.uk[^\\s]*', \"\", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the star_words\n",
    "def remove_star_words(s):\n",
    "    return re.sub('[^\\s]*[\\*]+[^\\s]*', \"\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(remove_star_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing all numbers\n",
    "def remove_nums(s):\n",
    "    return re.sub('[^\\s]*[0-9]+[^\\s]*', \"\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(remove_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the punctuations\n",
    "from string import punctuation\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    global punctuation\n",
    "    for p in punctuation:\n",
    "        s = s.replace(p, '')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to lower case\n",
    "dataset =dataset.map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n",
      "\n",
      "engineer quality control inspector  kuwaitthe prepositioning and marine corps logistics services pmcls program is based in jacksonville florida we provide maintenance and logistics services to the us marine corps usmc and us navy we are seeking a engineer quality control inspector for our kuwait location position responsibilities inspects maintenance activities such as handling storing servicing and repairing of usmc engineering equipment assigned to the marine expeditionary unit augmentation program · responsible for conducting quality control inspections on all usmc engineer equipment · responsible for collecting and analyzing data to make decisions that improve maintenance quality performance and customer satisfaction · analyze and display data to allow decision making based on maintenance history and quality performance data · monitors the activities of all personnel engaged in the input receipt and dissemination of gcssmc and related reports · use and interpret usmc mpr dasf and readiness reports to identify maintenance status trends and process deficiencies · coordinates with supervisors to  of procedures among various organizations or branches engaged in maintenance support activities and to ensure a close integration of operations · coordinates with management to train employees on the techniques and tools to identify analyze and lead efforts to solve problems and to provide improved customer satisfaction · conducts classes on maintenance management subjects · identify opportunities for process improvements establish and lead teams to work process improvement initiatives document team progress · collect monitor display interpret  process metrics to senior management team achieve quality performanceand productivity goals · coordinate and conduct joint limited technical inspections along with stock list    inventories for the issuing and recovery of designated engineer systems this includes post recovery reporting of equipment condition and cost to repair or replace items to a ready for issue acceptable material readiness status · performs other related duties as assigned\n",
      "\n",
      "scheduled weekly hours\n",
      "\n",
      "\n",
      "ENDDDDD/n\n",
      "<class 'str'>\n",
      "your role\n",
      "the quality analyst will be responsible for assisting the qshe manager and operations in researching quality operations and data discrepancies  data\n",
      "\n",
      "your responsibilities\n",
      "audit all outbound parcel ltl and international shipments to ensure customer satisfaction and that orders meet established standards of quality may be required to assist with process audits andor root cause analysis\n",
      "will generate inspection reports through manhattan andor sap\n",
      "will audit any material for accuracy and inspect for accuracy or damage will rebox relabel or identify product for scrap\n",
      "will perform quality inspections per sop\n",
      "update data logs and prepare material to be scrapped document internal audits and other quality assurance activities\n",
      "audit racks for any damaged product and move appropriate work area for repair\n",
      "will be backup support for inbound disposition clerk or any other department\n",
      "review shipping discrepancies from customer review manhattan for inventory adjustments\n",
      "investigate discrepancies and use information found to determine if  is valid\n",
      "be provide quality support ie identify part numbers question on packaging etc for all team members\n",
      "work with management to drive quality programs and customer satisfaction\n",
      "may be required to assist with sopswork instructions audits as required\n",
      "will perform other job tasks as assigned\n",
      "your skills and experiences\n",
      "high school diploma or ged required\n",
      "prior experience in a warehouse environment is preferred\n",
      "ability to use rf gun andor manhattan\n",
      "strong pc skills including proficiency in wms applications and microsoft office\n",
      "detailoriented problemsolving and analytical skills\n",
      "ability to work in a team setting  with various levels of the organization\n",
      "understand and adhere to department policy and procedures\n",
      "ability to establish priorities and  multiple tasks with minimal supervision\n",
      "must have good math skills\n",
      "forklift certified preferred\n",
      "fluent in english\n",
      "job type fulltime\n",
      "\n",
      "experience\n",
      "microsoft excel  years preferred\n",
      "location\n",
      "whitestown in preferred\n",
      "ENDDDDD/n\n",
      "<class 'str'>\n",
      "title data analyst location denver co downtown duration  months perm key skills database etl skills with sql server tsql stored procs power bi matrix dashboard design knowledge data analysis and documentation strong  skills exposure to json  strongly desirable exposure to python scripting desirable power bi andor azure ml\n",
      "ENDDDDD/n\n",
      "<class 'str'>\n",
      "campus\n",
      "san diego\n",
      "job id\n",
      "\n",
      "job title\n",
      " eisc learning spaces coordinator information technology consultant  career instructional technology services\n",
      "\n",
      "appointment type\n",
      "probationary\n",
      "time base\n",
      "fulltime\n",
      "\n",
      "date posted\n",
      "february  \n",
      "closing date\n",
      "open until filled\n",
      "benefits link\n",
      "csueu unit    \n",
      "link to apply online\n",
      "httpsbfasdsueduhrjobsjobopportunitiesaspx\n",
      "campus employment homepage\n",
      "httpjobssdsuedu\n",
      "description\n",
      "position summary\n",
      "\n",
      "under general supervision of the associate director the eisc learning spaces coordinator provides technical operational and scheduling support to conference rooms collaborative spaces and digital signage in the engineering and interdisciplinary sciences eisc complex\n",
      "\n",
      "as a member of the its learning spaces group this position also assists with the construction maintenance and support of classroom technology systems incumbent also assists with daytoday operations of its’s equipment loan service\n",
      "\n",
      "the person holding this position is considered a mandated reporter’ under the california child abuse and neglect reporting act and is required  with the requirements set forth in csu executive order  as a condition of employment\n",
      "\n",
      "for more information regarding the instructional technology services department click here httpsitssdsuedu\n",
      "\n",
      "this is a fulltime  timebase benefits eligible permanent probationary position this position is designated nonexempt under flsa and is eligible for  standard sdsu work hours are monday – friday  am to  pm but may vary based on operational needs\n",
      "\n",
      "education and experience\n",
      "\n",
      "to enter this classification a basic foundation of knowledge and skills in technical information systems and application program packages is a prerequisite this foundation would normally be obtained through a bachelor’s degree  science information systems educational  or related fields or similar certified coursework in applicable fields of study foundation knowledge and skills for the information technology consultant depending on the nature of the position assignment may include working knowledge  software application packages equipment platforms reference database systems and sources and training methods and a basic understanding of networks  and multimedia systems\n",
      "preferred qualifications and specialized skills\n",
      "\n",
      "• two or more years of experience providing academic technology support in a higher education setting\n",
      "• knowledge web conferencing tools and technology such as zoom webex skype for business google hangouts\n",
      "• knowledge of wireless technologies configuration and troubleshooting\n",
      "• knowledge of digital display technology and configuration ie signage and information kiosk\n",
      "• experience in the operation and maintenance of a broad range of audio and video equipment including distribution and projection systems\n",
      "• ability to work effectively with faculty staff and administrators\n",
      "• ability  clearly both orally and in writing\n",
      "• ability to analyze situations accurately and take appropriate action\n",
      "\n",
      "classroom technologies\n",
      "\n",
      "• knowledge of analog and digital technologies and the ability to appropriately apply them in the installation troubleshooting and maintenance of conference room and smart classroom systems\n",
      "• knowledge of and experience with a broad range  hardware and software products including both mac and windows operating systems and the microsoft office suite\n",
      "• ability to configure and interconnect conference room and smart classroom equipment and systems\n",
      "• ability to operate maintain and troubleshoot conference room and smart classroom equipment software and systems\n",
      "• ability to diagnose equipment andor system malfunctions and perform corrective action\n",
      "• ability to train college facilitators and its student assistants on smart classroom system installation troubleshooting and maintenance\n",
      "\n",
      "training and user support\n",
      "\n",
      "• ability to apply consultative skills to assess user needs and provide appropriate support\n",
      "\n",
      "compensation and benefits\n",
      "\n",
      "starting salary upon appointment not expected to exceed  per month csu classification salary range    per month salary placement is determined by the education experience and qualifications the candidate brings to the position internal equity and the hiring department’s fiscal resources\n",
      "\n",
      "san diego state university offers a rich benefits package that constitutes a major portion of  for more information regarding sdsu benefits please click here httpsbfasdsueduhrjobsbenefits\n",
      "\n",
      "supplemental information\n",
      "\n",
      "initial review of the required application materials including cover letters and resumes will begin on february   to receive full consideration apply by february   the position will remain open until filled\n",
      "\n",
      "the person holding this position is considered a ‘mandated reporter’ under the california child abuse and neglect reporting act and is required  with the requirements set forth in csu executive order  as a condition of employment\n",
      "\n",
      "san diego state university is not a sponsoring agency for staff or management positions eg  visa applicants must currently be authorized to work in the united states on a fulltime basis offers of employment are contingent upon the presentation of documents that demonstrate a persons identity and authorization to work in the united states which are consistent with the provisions of the immigration reform and control act\n",
      "\n",
      "a background check including a criminal records check must  satisfactorily before any candidate can be offered a position with the csu failure to  the background check may affect the application status of applicants or continued employment of current csu employees who apply for the position\n",
      "\n",
      "sdsu is a smokefree campus for more information please click here httpssmokefreesdsuedu\n",
      "\n",
      "sdsu is an equal opportunity employer and does not discriminate against persons on the basis of race religion national origin sexual orientation gender gender identity and expression marital status age disability pregnancy medical condition or covered veteran status\n",
      "\n",
      "applicants with disabilities and applicants who require  an application may contact meracle cothron at \n",
      "ENDDDDD/n\n",
      "<class 'str'>\n",
      "position description\n",
      "position purpose\n",
      "the home depot is always striving to deliver outstanding customer service drive improvement and develop talent that will grow our business into the future for individuals who are results oriented and interested in developing leadership skills within a dynamic teamfocused environment we offer our assurance and advisory management program amp amp is designed to drive continuous improvement in the company while developing the career and leadership skills of associates in the program across all major functional areas eg merchandising supply chain store operations finance and it the senior analyst of data analytics will be responsible for executing data intensive project work providing ahhoc data request support and developing and maintaining amp analytics tools eg automation through robotics various ongoing analyses dashboards etc this individual should possess strong data mining skills and be familiar with the programming tools statistical software and technology used by the amp team eg sql tableau r python\n",
      "major tasks responsibilites and key accountabilities\n",
      " – execute specified segments of a project understand project objectives meet set  results and present deliverables for the identified segment create sophisticated data collection plans identify sources of data operational financial industry etc gather analyze and manipulate data review data for trends and exceptions and draw sound conclusions use statistical data tools to graphically display and analyze results\n",
      " – support amp staff with adhoc data support interact with team members across amp functional areas to understand their requirements and develop solutions to support their data analysis needs to drive efficiency and improved results assist with the development and delivery of data analytics training for the department\n",
      " – develop and maintain amp analytics tools and ongoing monitors utilize robotics to automate testing and analytics eg time  expense fraud monitoring develop and maintain data mining reporting capabilities and repetitive analytics to support the department\n",
      "nature and scope\n",
      "this position reports to the senior manager\n",
      "this position has  direct reports\n",
      "\n",
      "environmental job requirements\n",
      "environment\n",
      "located in  indoor area any unpleasant conditions would be infrequent and not objectionable\n",
      "travel\n",
      "typically requires overnight travel less than  of the time\n",
      "\n",
      "essential skills\n",
      "minimum qualifications\n",
      "must be eighteen years of age or older\n",
      "must be legally permitted to work in the united states\n",
      "education required\n",
      "the knowledge skills and abilities typically acquired through  of a bachelors degree program or equivalent degree in a field of study related to the job\n",
      "\n",
      "years of relevant work experience  years\n",
      "\n",
      "physical requirements\n",
      "most of the time is spent sitting in  position and there is frequent opportunity to move about on rare occasions there may be a need to move or lift light articles\n",
      "\n",
      "preferred qualifications\n",
      " and interpersonal skills ability to work well with others\n",
      "strong quantitative and analytical skills\n",
      "experience with the following tools and technologies sql tableau programming language r python or sas sap\n",
      "knowledge skills abilities and competencies\n",
      " and interpersonal skills ability to work well with others\n",
      "strong quantitative and analytical skills\n",
      "experience with the following tools and technologies sql tableau programming language r python or sas sap\n",
      "\n",
      "we are an equal opportunity employer and do not discriminate against any employee or applicant for employment because of race color sex age national origin religion sexual orientation gender identity status as a veteran and basis of disability or any other federal state or local protected class\n",
      "ENDDDDD/n\n",
      "<class 'str'>\n",
      "alkami builds and delivers the nation’s most innovative cloudbased digital banking online and mobile apps for credit unions and banks with over  users on our platform through our bold investments in technology and people our clients confidently grow adapt quickly and build thriving digital   against the megabanks founded  years ago with headquarters in plano alkami is one of the fastest growing  in texas and among the fastest growing privately held  in the us to share just a few of our recent recognitions best place to work in fintech inc  america’s fastestgrowing private companies deloitte technology fast  tech titans top  and smu cox caruth institute dallas  with every alkamist having ownership in alkami we are obsessively intentional about our culture optimisticperseverance caringcollaboration  courageousinnovation trustedaccountability and realfun beyond intentional culture  is to attract and retain amazing talent by fostering a highgrowth dynamic and rewarding environment providing great benefits making meaningful investments in learning and development offering free lunches every work day celebrating our successes together in remarkable ways and acting together by taking time to give back and volunteer\n",
      "\n",
      "position overview\n",
      "\n",
      "the service management analyst will be responsible for assisting the service manager in developing and maturing the key service management functions within the service operations organization at alkami responsible for major incident management incident management ticket management problem management rca management delivery vendor management reporting and maturing all service operations processes in line with industry best practices client focused role also responsible for key performance metrics and reporting both internally and externally the successful candidate will be technically sound  interacting at all levels across organizations again both internally and externally\n",
      "\n",
      "key responsibilities duties\n",
      "\n",
      "taking an active role in major incident management mim ensuring the appropriate alkami resources are engaged and client stakeholders are kept apprised of status this will also include managing major incident reviews and tracking followup actions actively work with the  noc team and with performance engineers to actively monitor performance issues in production and staging maintain a proactive approach to operational and service issues with a focus on prevention rather than breakfix assistrun the rca process by driving incident resolution template irt creation  initial rca data gathering and creation\n",
      "\n",
      "provide a regular and clear status on the operational performance of all areas of the service to the client and internal parties including contractually required sla and issue reporting publish recurring service reviews and internal operational reporting as required by contractual terms or client requests maintain strong client and supplier relationships to ensure slas and service excellence are managed and maintained\n",
      "\n",
      " accurately clearly and effectively in writing in person and on the phone mentor and work well with other members of the service operations organization\n",
      "\n",
      "qualifications\n",
      "work designated shift monday  friday  am to  pm or agreed upon timeframe as some flexibility exists\n",
      "ability to take direction from a strong leader but also self motivate to achieve organizational goals\n",
      "ability to understand and meet operational goals and deadlines\n",
      " and customer facing skills ability  at all levels within the organization\n",
      "strong problem solving skills\n",
      "ability to remain calm under trying circumstances\n",
      "ability to effectively manage customers internal and external and their expectations\n",
      "flexible ability to adapt to change\n",
      "high school diploma ged equivalent certification or military experience\n",
      "desired skills\n",
      "experiencefamiliarity working with the following\n",
      "google suite including  google docs sheets slides gmail\n",
      "above average skills in excelgoogle sheets a plus\n",
      "understanding operational and sla reporting methodologies a plus\n",
      "experience using jira\n",
      "basic understanding of itil foundations and incident management a plus\n",
      "familiarity with various online banking applications are strong plusses\n",
      "college degree a plus\n",
      "understanding of application performance management tools such as new relic datadog dynatrace or appdynamics a plus but not required\n",
      "cool things to know\n",
      "not just any company alkami has an awesome diverse and inclusive environment we have a fun culture and offer great benefits did you know every alkamist has ownership in alkami we also have on and off site employee events and activities\n",
      "free lunch who said there is no free lunch at alkami every day we offer free lunch\n",
      "relocation unfortunately we dont offer relocation assistance we are ready for you to contribute from our super cool plano tx location\n",
      "work authorization we cannot offer employer sponsorship at this time candidates must be eligible to work in the us for fulltime employment\n",
      "recruiters we are not looking for outside recruiting firms to help us in this search— we know who you are and we love you but we don’t need you right now\n",
      "the important stuff\n",
      "\n",
      "alkami technology is an equal opportunity employer and prohibits discrimination and harassment of any kindalkami  to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment all employment decisions at alkami are based on business needs job requirements and individual qualifications without regard to race color religion or belief national social or ethnic origin sex including pregnancy age physical mental or sensory disability hiv status sexual orientation gender identity andor expression marital civil union or domestic partnership status past or present military service family medical history or genetic information family or parental status or any other status protected by the laws or regulations in the locations where we operate alkami will not tolerate discrimination or harassment based on any of these characteristics alkami encourages applicants of all ages\n",
      "ENDDDDD/n\n",
      "<class 'str'>\n",
      "about the company\n",
      "this  has been a staple in the columbus area for almost  years\n",
      " has a specific manufacturing technology different from peers in their field and therefore have had overall steady growth\n",
      "a tightknit accounting team this role reports directly to the cfo\n",
      "our client has taken extra precautions to protect their employees\n",
      "fantastic worklife balance\n",
      "our client also offers an outstanding benefit package to attract and retain high quality employees\n",
      "they like to recognize their employees by  incentives bonuses yearend celebrations and other employee events throughout the year\n",
      "fantastic location  lots of lunch options  retail stores nearby\n",
      "business casual work environment\n",
      "responsibilities of the financial analyst\n",
      "inventory control\n",
      "prepare financial reports and analysis\n",
      "assisting the cfo with various accounting projects\n",
      "assist with new erp system transition\n",
      "qualifications preferred for the financial analyst\n",
      "advanced excel\n",
      "  years experience manufacturing a plus\n",
      "positive team environment attitude\n",
      "id \n",
      "ENDDDDD/n\n",
      "<class 'str'>\n",
      "position sr data engineer location dallas tx duration  months contract sr data engineer have a strong data integration background and enjoy debugging troubleshooting designing and implementing solutions  technical issues you are highly motivated and have a passion for data warehousing and the value it brings to an organization plan and execute secure good practice data integration strategies and approaches acquire ingest and process data from multiple sources and systems into big data platforms involved in endtoend data management bringing a desire to help move forward in best practices optimization and maintenance of existing data pipelines develop data integration mappingsworkflows data mart development add calculations columns and tables to meet front end demand document work according to best practices collaborate with other teams to map data fields to hypotheses and curate wrangle and prepare data for use in advanced analytical models size and scope development needs for both operational and project initiatives required skills  years development experience working with advanced sql  year experience working with python scripting  years building operational etl data pipelines across several sources and constructing relational and dimensional data models  years data warehousing experience with cloud products like snowflake azure dw or redshift  years working with on premise and cloud base data warehouse solutions\n",
      "ENDDDDD/n\n",
      "<class 'str'>\n",
      "• minimum  years of experience working with hadoop hivesqoop spark scala python kafka and  proven experience in handling terabyte and petabyte of data on cloudera  proven experience in handling variety of data  experience in building large scale data lake  troubleshooting hive performance issues and developing hql  experience with spark and  experience in implementing cicd process and job automation through  experience in hadoop cluster administration is a big  experience with integration of data from multiple data  assist analytics and data scientist team and business   skills and the ability  appropriately at all levels of the organization this includes written and  as well as  the ability to act as liaison conveying information needs of the business to it and data constraints to the business applies equal conveyance regarding business strategy and it strategy business processes and work  team player able to work effectively at all levels of an organization with the ability to influence others to move toward  strong situational analysis and decision making \n",
      "ENDDDDD/n\n",
      "<class 'str'>\n",
      "job description\n",
      "\n",
      "job title\n",
      "usgaap financial and reference data control analyst\n",
      "\n",
      "corporate title\n",
      "analyst\n",
      "\n",
      "location\n",
      "jacksonville fl\n",
      "\n",
      "overview\n",
      "\n",
      "the usgaap financial and reference data control analyst role coordinates and assists with recurring outputs and reports you will assist the financial reporting analysts specialists and leads in the timely delivery of reports and edit as requested by managers in the group the financial regulatory and risk reporting support analyst organizes checks on reports and ensures consistency across all reporting in accordance with relevant accounting standards you may partner with various stakeholders in the bank to collect the necessary information for reporting this role is needed to support financial and regulatory reporting from usgaap standpoint\n",
      "\n",
      "what we offer you\n",
      "we  health and wellness benefits empowering you to value life in and out of the office\n",
      "onsite gym cafeteria health center  meeting areas\n",
      "active engagement with the  through deutsche banks specialized employee groups\n",
      "an open seating environment that encourages networking and collaboration across functions and businesses\n",
      "hear from our people and look inside our office dbthe muse\n",
      "\n",
      "your key responsibilities\n",
      "prepare and maintain the banks usgaap consolidation tool regional consolidation system  rcs for financial regulatory as well as internal reporting requirements this involves remediating data quality issues system enhancements testing scenario analysis capabilities and establishing sound control framework around usgaap consolidation processes\n",
      "coordinate efforts between various relevant stakeholders such as legal vehicle controllers quality assurance coordinators global technology finance directors etc to resolve consolidation breaksissues\n",
      "maintain oversight of usgaap related chart of account and facilitate changes by performing impact analysis on various reporting parameters engage appropriate stakeholders from reporting standpoint to review and approve relevant changes\n",
      "oversee and maintain various referential data touch points in multiple reporting systems to ensure timely and accurate reporting and drive process improvements and track projects to  tasks performed by the team\n",
      "perform deep dive analysis to identify and eliminate redundancies in existing processes to create capacity which can be utilized elsewhere\n",
      "create andor maintain key operating procedures for all functions performed by the usgaap local control team\n",
      "your skills and experience\n",
      "bachelors degree and relevant accounting andor finance industry experience or internship experience\n",
      "you will be expected to be able to work independently with multiple deadlines and have the ability to focus and prioritize in a high pressure environment\n",
      "strong analytical skills detailoriented  and solid organizational and interpersonal skills\n",
      "ability to manage and deliver on senior management expectations\n",
      "excellent pc skills to include experience with ms word excel and powerpoint\n",
      "our values define the working environment we strive to create  diverse supportive and  of different views we embrace a culture reflecting a variety of perspectives insights and backgrounds to drive innovation we build talented and diverse teams to drive business results and encourage our people to develop to their full potential talk to us about flexible work arrangements and other initiatives we offer\n",
      "\n",
      "we promote good working relationships and encourage high standards of conduct and work performance we  applications from talented people from all cultures countries races genders sexual orientations disabilities beliefs and generations and  to providing a working environment free from harassment discrimination and retaliation\n",
      "\n",
      "click here to find out more about our diversity and inclusion policy and initiatives\n",
      "\n",
      "we are an equal opportunity employer  veteransdisabled and other protected categories click these links to view the following notices eeo is the law poster and supplement employee rights and responsibilities under the family and medical leave act employee polygraph protection act and pay transparency nondiscrimination provision\n",
      "ENDDDDD/n\n",
      "<class 'str'>\n",
      "job description\n",
      "\n",
      "are you passionate about improving the quality of healthcare\n",
      "\n",
      "are you ready to leverage your talents to make healthcare better for everyone\n",
      "\n",
      "do you want the opportunity to give back to \n",
      "\n",
      "do you want to have fun at work\n",
      "\n",
      "then join the growing team at health services advisory group hsag that is transforming the delivery of healthcare in the united states\n",
      "\n",
      "summary\n",
      "\n",
      "the data analyst is a key contributor to data analysis development quality control and reporting work that spans the broad spectrum of healthcare data projects in hsag’s endstage renal disease esrd national coordinating center ncc division this position will actively engage with esrd subject matter experts analytic staff and other stakeholders to support cms and the esrd networks in the achievement of contract goals and the overall improvement in quality of care and quality of life for dialysis and kidney transplant patients\n",
      "\n",
      "to perform the duties of this position successfully an individual must be able to perform each essential duty satisfactorily and independently the requirements listed are representative of the knowledge skills andor abilities required details regarding potential project assignments will be discussed with potential candidates during the interview process\n",
      "\n",
      "essential competencies duties and responsibilities\n",
      "conduct data analyses for esrd research and reporting tasks and contract deliverables\n",
      "provide analytical expertise for all datarelated tasks on assigned projects\n",
      "prepare review and interpret technical reports visualizations and contract deliverables\n",
      "maintain uptodate knowledge on various analytic issues and analysis programming methodology\n",
      "perform quality control activities including parallel coding independent review of analysis results and code reviews\n",
      "maintain uptodate knowledge of all assigned analytic tasks and related initiatives\n",
      "participate in ongoing continuous improvement of the quality and efficiency of analytic products and services\n",
      "perform assessment and identify methods to efficiently  assigned tasks and deliver quality work products\n",
      "provide excellent customer service with timely accurate and courteous response to all team members\n",
      "\n",
      "job requirements\n",
      "\n",
      "\n",
      "education andor experience\n",
      "bachelor’s degree in statistics healthcare economics mathematics  field\n",
      "a minimum of three years of recent work experience in conducting healthcare data analysis using sas or sql\n",
      "other qualifications\n",
      "knowledge in data analyses including trending reporting and measure calculations\n",
      "proficient in microsoft office ie word excel powerpoint access\n",
      "advanced experience using sas or sql\n",
      "experience with tableau dashboard and report development preferred\n",
      "experience working with large nationallevel datasets\n",
      "experience with protocols for handling protected health information or other highly sensitive information\n",
      "experience with quality measure analysis is preferred\n",
      "demonstrated ability  technical findings to leadership management and nontechnical experts\n",
      "excellent oral and  and interpersonal skills\n",
      "work environment\n",
      "\n",
      "the work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this position reasonable  may be made to enable individuals with disabilities to perform the essential functions\n",
      "\n",
      "hsag all user information security responsibilities\n",
      "\n",
      "all workforce members volunteers contractors or thirdparty agents of hsag inc who are authorized to access information systems andor  data on paper or in electronic format are responsible for the following\n",
      "adhering to policies procedures and guidelines pertaining to the protection of hsag company data\n",
      "reporting actual or suspected breaches or vulnerabilities in the confidentiality integrity or availability of hsag data to your immediate supervisormanager corporate compliance or information technologysecurity personnel\n",
      "reporting actual or suspected breaches or vulnerabilities in confidentiality integrity or availability of corporate data may be reported anonymously via the navex global compliance hotline at \n",
      "hsag publishes various policies guidelines and procedures related to the protection of corporate data and information systems they can be found on the corporate sharepoint website information on requirements that may be unique to your business unit or a system you have access to can be found by talking to your supervisormanager or designated system administrator\n",
      "\n",
      "disclaimer\n",
      "\n",
      "this is not necessarily an exhaustive list of all responsibilities skills duties requirements efforts or working conditions associated with the position while this is intended to be an accurate reflection of the current position management reserves the right to revise the position or to require that other or different tasks be performed when circumstances change eg emergencies changes in personnel work load rush jobs requiring nonregular work hours or technological developments\n",
      "\n",
      "hsag is an eeo employer of veterans protected under section \n",
      "\n",
      "if you have special needs and require  our employment application process please feel free to contact us\n",
      "\n",
      "eoe mfvetdisability\n",
      "ENDDDDD/n\n",
      "<class 'str'>\n",
      "role cyber security forensic analyst\n",
      "\n",
      "location austin tx\n",
      "\n",
      "job description\n",
      "ibm is seeking a cyber security forensic analyst professional to work on the cyber security incident response team csirt this position requires a strong technical security professional who will be responsible for conducting highly technical and confidential investigations eg data loss advanced persistent threats malware analysis etc\n",
      "\n",
      "the role will be responsible for conducting forensic investigations and analysis in support of cyber incidents that are reported into the csirt team this role will require the ability to triage and conduct thorough examinations of all types of digital media within a heterogeneous environment the ability to determine containment andor remediation activities that may be required as well as identify potential threats reporting and collaborating with the different areas of business will be required as well as providing relevant lesson learned output that can be fed into the ibm threat landscape\n",
      "\n",
      "essential duties and responsibilities\n",
      "conduct examination of digital media hard drives network traffic mobile phones etc\n",
      "capture  analyze network traffic for indications \n",
      "review logbased data both in raw form and utilizing siem or aggregation tools\n",
      "employ best practices and forensically sound principals such as evidence handling and chain of custody\n",
      "perform live network assessments using leading packet capture and analysis software tools\n",
      "establish timelines and patterns of activity based on multiple data sources\n",
      "identify document and prepare reports on relevant findings\n",
      "utilize varied forensic software such as ftk encase ief etc\n",
      " with clients to establish timelines manage expectations and report findings\n",
      "required knowledge skills and abilities\n",
      " forensic investigations experience\n",
      "expertlevel knowledge  attack vectors and penetration techniques\n",
      "solid working knowledge of networking technology and tools firewalls proxies idsips encryption\n",
      "demonstrated knowledge of forensic tools such as encase ftk axiom black bag sift\n",
      "experience with malware analysis reverse engineering\n",
      "excellent technical writing and presentation skills\n",
      "excellent general writing skills in presenting information in a nontechnical manner business case construction proposals and plans\n",
      "ability to successfully lead and facilitate information gathering meetings with client seniorlevel employees\n",
      "event analysis and correlation\n",
      "experience managing large and small scale cyber security incidents\n",
      "ability to coach and training junior level analysts in industry best practices and methodologies\n",
      "an ability to understand and correlate strategic decisionsmethodologies into their practical application at an operational level\n",
      "demonstrated understanding of database structures and sql\n",
      "experience with linux operating systems\n",
      "required\n",
      "at least  years of experience in it security digital forensics\n",
      "at least  years of experience in incident response in a global corporate enterprise\n",
      "preferred\n",
      "certified in ence cfce cce dfcp gcia gcih grem csih\n",
      "strong understanding of networking protocols\n",
      "experience in fastpaced investigations\n",
      "experience with programming or scripting languages\n",
      "familiar with qrader siem tool is a plus\n",
      "demonstrated system administration skills\n",
      "ability to present highly technical information to nontechnical audiences\n",
      "ENDDDDD/n\n",
      "<class 'str'>\n",
      "dematic is an intralogistics innovator that designs builds and supports intelligent automated solutions for manufacturing warehouse and distribution environments for customers that are powering the future  with engineering centers manufacturing facilities and service centers located in more than  countries dematic’s global network of  employees have helped achieve more than  worldwide customer installations for some of the world’s leading brands headquartered in atlanta dematic is a member of kion group a global leader in industrial trucks supply chain solutions and related services and a leading provider of warehouse automation\n",
      "\n",
      "dematic corp is looking for a software analyst\n",
      "essential role and responsibilities\n",
      "this role provides preandor post sales technical product advice for the development and implementation of customer solutions participates in the preparation and presentation of technical proposals including product demonstrations and product prototypes participates in the preparation and presentation of customer needs plan  teams to  plan is feasible within cost time and environment constraints resolves  technical problems may provide installation support and postsales consulting provides followup support in disseminating  technical information on specific applications\n",
      " of responses to rfp rfi and other sales related documentation for assigned opportunities using standard responses and liaising with technical resources as needed\n",
      "performs analysis of customers business requirements and develops solutions to meet or exceed customers needs conducts or oversees the development of proposal documents\n",
      "estimates time frames quality and quantity of resources required to successfully implement  project develops project plan incorporating all project variables\n",
      "conducts periodic status checks with customer and team to assess progress against plan\n",
      "develop pricing for each assigned opportunity including software license professional services dematic hardware third party hardware and any vendor contract pricing\n",
      "define pricing terms contract language and major proposalproject assumptions for each assigned opportunity\n",
      "work with business development and sales teams to maintain pipeline in \n",
      "provide material to marketing for white papers blogs and other campaigns\n",
      "perform site visits with sales executives to drive understanding of how software solution fits in the opportunity\n",
      "determines methodology for collecting analyzing and summarizing data critical to design\n",
      "uses written descriptions spreadsheets charts and material flow diagrams skillfully\n",
      "stay abreast of current  future operating strategies and technologies by attending industry conferences seminars etc\n",
      "understands customers operations thoroughly\n",
      "develops a wide range of concepts that meet or exceed the design criteria concepts may range from manual to fully automated solutions\n",
      "to facilitate concept understanding uses drawings and sketches skillfully\n",
      "evaluates concepts and  the best solution skilled in using evaluation techniques ranging from simple pro and  to sophisticated return on investment roi calculations\n",
      "produces a design report that professionally summarizes the project\n",
      "thoroughly understands the practices methodologies and requirements of the supply chain solutions department and serves as advisor to all group members\n",
      "work with sales executive to finalize solution strategy and operation research engineers to calculate roi\n",
      "create sales handoff artifacts for each owned opportunity that is closed ensuring professional services team understands scope open questions payment terms and next steps\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "qualification requirements\n",
      "bachelor’s degree mis or engineering a plus master’s degree a plus\n",
      "demonstrates a good grasp of knowledge and principles of field of specialization and applies through  of assignments\n",
      "successfully applies knowledge of fundamental concepts practices and procedures of particular area of specialization\n",
      "typically  years of successful experience in related field and successful demonstration of key responsibilities and knowledge as presented above\n",
      "advanced degree may be substituted for experience where applicable\n",
      "achievement in both academic studies and the workplace\n",
      "enterprise software experience a plus\n",
      "preferred qualifications\n",
      "ability to create detailed sales proposals and corresponding power point presentations\n",
      "experience  problem solving with the ultimate goal of driving to solution roipayback analysis\n",
      "ability to multitask on different opportunities in various stages of the sales cycle\n",
      "understanding of sdlc\n",
      "solution driven approach\n",
      "experience with enterprise software solutions\n",
      "experience with supply chain and logistics integrated systems solutions\n",
      "experience with industrial internet of things iiot solutions\n",
      "understanding of enterprise software ecosystems\n",
      "experience with sales life cycle specifically in regard to solutionoriented selling\n",
      "sales engineering experience with wms wes \n",
      "professional services sales engineering project management software development quality assurance background\n",
      "ability to drive technical demos of software products\n",
      "bilingual or multilingual abilities a plus\n",
      "ENDDDDD/n\n",
      "<class 'str'>\n",
      "job description\n",
      "position title staff  biologist i ii and iii orpostdoctoral fellow bioinformaticsbiostatisticscomputer science\n",
      "\n",
      "duties  responsibilities for bioinformatics scientists the projects include developing novel method for analysis and integration of cancer genomics and other forms of highdimensional omics data and developing prediction models for patients’ clinical  for biostatistics scientists the projects include assembling and statistical analyses of big clinical data  scientists the projects including creating databases and websites for management of big biological data\n",
      "\n",
      "at utsw there are great opportunities for scientists to collaborate with outstanding biomedical investigators and work on exciting research projects ut southwestern provides a friendly dynamic collaborative and integrative research and training environment with stateoftheart facilities\n",
      "\n",
      "position qualifications candidates should have a doctoral or master degree in either one of the following fields including geneticsgenomics  science  biology or a related field programming skills in python perl or r is preferred\n",
      "\n",
      "related websites\n",
      "\n",
      "qbrc httpsqbrcswmededu\n",
      "\n",
      "application deadline until filled\n",
      "\n",
      "ut southwestern western medical center is an affirmative actionequal opportunity employer women minorities veterans and individuals with disabilities are encouraged to apply\n",
      "ENDDDDD/n\n",
      "<class 'str'>\n",
      "healthcare data analytics analyst senior\n",
      "location\n",
      "\n",
      "\n",
      "philadelphia pa\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "yes\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "your career starts now we’re looking for the next generation of health care leaders\n",
      "\n",
      "at amerihealth caritas we’re passionate about helping people get care stay well and build  as one of the nations leaders in health care solutions we offer our associates the opportunity to impact the lives of millions of people through our national footprint of products services and awardwinning programs amerihealth caritas is seeking talented passionate individuals to join our team together we can build  if you want to make a difference we’d like to hear from you\n",
      "\n",
      "headquartered in philadelphia amerihealth caritas is a missiondriven organization with more than  years of experience we   care to those who need it most we offer integrated managed care products pharmaceutical benefit management and specialty pharmacy services behavioral health services and other administrative services discover more about us at \n",
      "\n",
      "responsibilities\n",
      "\n",
      "support trend analytics and cost containment initiatives as part of a dynamic team build deploy and maintain dashboards and analyses that support identification of meaningful medical cost trends collaborate with subject matter experts to identify root causes of trends may work with multiple business segments and departments the ideal candidate will have a thirst for continuous learning investigative analytics ad hoc reporting and creative problem solving heshe will be sought out as an expert on the projects they support sharing work with a wide array of audiences this is a great opportunity to utilize strong skills in programming analytics and reporting\n",
      "\n",
      "primary responsibilities\n",
      "build and maintain dashboards measuring plan performance\n",
      "investigate trend drivers and root causes\n",
      "present analyses to appropriate stakeholders in an understandable manner in order to advance projects and transform data into actionable \n",
      "prepare exhibits for presentation to key stakeholders throughout project lifecycle\n",
      "anticipate customer needs and proactively develop solutions to meet them\n",
      "serve as a key resource on critical programming and methodology issues\n",
      " problems and develop innovative solutions\n",
      "educationexperience\n",
      "bachelor degree required master’s degree preferred in statistics mathematics computer science or related field or equivalent experience\n",
      "having passed actuarial exams is a plus\n",
      "three to five years healthcare experience\n",
      " years’ experience working within a managed care organization health insurer or as a consultant\n",
      " years claims analysis experience\n",
      " years working infrom a data warehouse environment\n",
      " years sas programming experience\n",
      "problem solving skills including the ability to work independently and systematically  problems draw relevant conclusions and successfully deviseimplement solutions calmly and effectively\n",
      "experience mining large data sets\n",
      "advanced capabilities with microsoft excel proficiency with microsoft powerpoint\n",
      "established ability to manage multiple initiatives shifting back and forth effectively among activities to produce positive results in a dynamic environment\n",
      "excellent written and  skills\n",
      "strong data presentation skills\n",
      "solid understanding of relational database fundamentals\n",
      "proficiency in database applications such as oracle hadoop\n",
      "preferred qualifications\n",
      "experience using sas enterprise guide\n",
      "experience developing tableau dashboards\n",
      "time series forecasting experience\n",
      "familiarity with statistical process control or six sigma\n",
      "familiarity with big data mining tools\n",
      "ENDDDDD/n\n",
      "<class 'str'>\n",
      "descriptionin this role you will be part of an advanced manufacturing artificial intelligence ai and advanced data analytics team consisting of colleagues possessing varying skill sets including data scientists data engineers frontend and backend developers and other business analysts\n",
      "\n",
      "in this role you will develop end to end web applications and design mockups with enhanced ui features including writing all the frontend code and building the user interface you will periodically produce storyboards wifeframes flowcharts design prototypes and other design elements\n",
      "\n",
      "our ideal candidate is someone who can\n",
      "design new and improve current web site applications and mobile applications ios\n",
      " ideas and designs and work with crossfunctional teams and customers\n",
      "conceptualize and collaborate using strategic thinking for marketing and other business priorities\n",
      "improve digital user experiences\n",
      "produce a portfolio showcasing frontend development skills\n",
      "exhibit outstanding technical and  skills to our internal customers\n",
      "demonstrated expertise in debugging code errors and troubleshooting software issues\n",
      "conduct research on evolving design trends and apply when appropriate\n",
      "design one off digital products for web sites such as banner ads icons illustrations etc\n",
      "basic qualifications\n",
      "bachelors or masters degree in computer science information systems or equivalent experience\n",
      " years experience as a uiux net developer\n",
      "build and implement frontend web single page applications that integrate with backend services and thirdparty partners\n",
      "demonstrated expertise in a serverside web technology net php etc\n",
      "experience or proficiency within  or more of the following java javascript html  nodejs bootstrap c   web services json api\n",
      "experience using web design software\n",
      "ability to produce responsive designs\n",
      "strong visual design skills iconography typography color theory etc\n",
      "focused on results and able to work closely with others in collaborative environment\n",
      "energetic  selfstarting\n",
      "desired skills\n",
      "basic knowledge of the software development life cycle sdlc process\n",
      "basic knowledge of the web development life cycle process\n",
      "multiple development methodologies including scrum andor agile and testdriven development experience using the agile philosophy for web design and development\n",
      "technical leadership of small to mediumsize teams\n",
      "lean six sigma green belt or black belt certification\n",
      "operations background\n",
      "basic qualifications\n",
      "jobqualifications\n",
      "\n",
      "lockheed martin is an equal opportunityaffirmative action employer all qualified applicants will receive consideration for employment without regard to race color religion sex pregnancy sexual orientation gender identity national origin age protected veteran status or disability status\n",
      "join us at lockheed martin where your mission is ours our customers tackle the hardest missions those that demand extraordinary amounts of courage resilience and precision theyre dangerous critical sometimes they even provide an opportunity to change the world and save lives those are the missions we care about\n",
      "\n",
      "as a leading technology  lockheed martins vast team works with partners around the world to bring proven performance to our customers toughest challenges lockheed martin has employees based in many states throughout the us and internationally with business locations in many nations and territories\n",
      "experience level\n",
      "experienced professional\n",
      "ENDDDDD/n\n",
      "<class 'str'>\n",
      "job description\n",
      "mirati therapeutics nasdaq mrtx is a san diegobased clinicalstage  dedicated to advancing novel therapeutics that extend the lives of patients by directly addressing the genetic and immunological drivers of cancer mirati is developing sitravatinib designed to selectively target a spectrum of tyrosine kinases implicated in both tumor growth and the suppression of immune responses to tumors sitravatinib has demonstrated durable responses in lung cancer patients whose cancer has progressed despite treatment with checkpoint inhibitors  an area of significant unmet medical need sitravatinib is being evaluated in multiple clinical trials to treat patients who are refractory to prior immune checkpoint inhibitor therapy including a potentially registrationenabling phase  trial of sitravatinib  with a checkpoint inhibitor in nonsmall cell lung cancer nsclc that is currently enrolling patients\n",
      "\n",
      "mirati is also developing novel direct inhibitors of kras mutations including  a potent and selective inhibitor of kras  this historically difficult to drug target is present in approximately  of nsclc adenocarcinomas  of colorectal cancer as well as smaller percentages of several other difficulttotreat cancers  is being evaluated in a phase  clinical trial as a treatment for patients with kras  tumors our research on  has led to breakthroughs in targeting other kras mutations including  which drives tumor growth in more patients than  and includes pancreatic colorectal and other types of cancer\n",
      "\n",
      "we are mirati\n",
      "\n",
      "our mission is to discover design and deliver breakthrough therapies to transform the lives of cancer patients and their loved ones we have built a culture fueled by accountability urgency collaboration and openmindedness and have established ourselves as an innovator within our industry as we grow we are looking to build diverse teams with skilled individuals that are passionate about their work\n",
      "\n",
      "why join us\n",
      "\n",
      "the drug discovery team at mirati is responsible for the invention optimization and characterization of quality small molecules as clinical candidates for mirati research programs the principal scientist will be responsible for bioanalysis pk calculations and lcms method development and will support fitforpurpose adme assay and formulation activities enabling advancement of oncology drug discovery programs extensive experience within bioanalysis and pk and strong lcms skills are desired\n",
      "\n",
      "your responsibilities\n",
      "provide bioanalysis of samples from pk pkpd and efficacy studies\n",
      "develop robust lcms methods supporting analysis of plasma and tumors for drug content\n",
      "calculate pk parameters analyze pkpd data and present to project teams\n",
      "provide nonroutine in vitro adme assays supporting lead progression to ind\n",
      "support early formulation evaluation for discovery programs and pharmacologypktoxicology studies\n",
      "work closely with project leaders to provide dmpk expertise as a key member of drug discovery teams\n",
      "add bioanalytical and ms expertise to our productive internal mirati dmpk lab\n",
      "maintain  with cros and maintain corporate data base\n",
      "author ind reports prepare and deliver internal presentations and external publications as driven by the project and corporate strategies\n",
      "what is required\n",
      "d with  years ms with  years or bs with  years of experience in a relevant laboratory environment with analytical chemistry dmpk and drug discovery background\n",
      "relevant pharmaceutical or biotech industry experience preferred\n",
      "a proven track record of experience and expertise in bioanalysis in vitro adme and lcms method development trouble shooting and equipment maintenance\n",
      "demonstrated dmpk related experience in advancing  through preclinical discovery stages to candidate selection preferred\n",
      "experience with sciex instrumentation regulated and nonregulated bioanalysis and a solid understanding of fundamentals of pk and adme preferred\n",
      "demonstration of  skills through internal and external presentations and publications\n",
      "miratis policy is to provide equal employment opportunities to all applicants and employees without regards to race color religion creed gender identity or expression age national origin or ancestry citizenship disability sexual orientation marital status pregnancy veteran status membership in the uniformed services genetic informations or any other basis protected by applicable law\n",
      "\n",
      "notice to third party agencies please note that mirati therapeutics inc does not accept unsolicited resumes from recruiters or employment agencies\n",
      "\n",
      "job posted by applicantpro\n",
      "ENDDDDD/n\n",
      "<class 'str'>\n",
      "a role in our cyber investigations function means you will have the opportunity to work with a group of individuals whose collective mission is to investigate information security risks or wrongdoing against our firm we are a globally dispersed group of hybrid cyber investigators  forensic specialists that provide independent root cause and contributing factors reporting to various lines of business our teams are regionally managed and globally governed we conduct professional and independent cyber investigations in order to ensure the confidentiality integrity and availability of citi controlled or owned information youll make connections with fellow colleagues that share your diverse background and experiences on our team we relish unique individuals collaborative teams and inclusive leaders because they are the engines of new ideas with operations around the world and staff from a variety of disciplines you will benefit from working alongside and learning from the best and the brightest in the cyber security industry as a cyber manager you will provide strategic leadership this position will tap into your expertise while continuing to hone your skills in establishing strong partnerships mentoring motivating and managing high performing teams one guarantee is that no two days will be the same as a member of the strategic initiatives team in the cyber security fusion center your primary responsibility is to identify systemic and emerging issues and drive solutions through persuasion and influence related activities include but are not limited to • influence decision makers across the organization via briefings and written analysis to eliminate and mitigate risks • partner with cyber investigators fusion center analysts business smes and enterprise engineers to assess criticality of issues and potential solutions • manage and conduct analysis across multiple incidents to identify inadequate security controls • document findings for a broad audience including technical executive and regulatory groups education and experience required o bachelors degree in a technically rigorous domain such as computer science information security engineering etc •  years of professional experience in cybersecurity andor information security or demonstrated equivalent capability •  years managing a team professional staff cyber program or resources o minimum  years of professional experience as a digital forensic investigator andor incident responder or demonstrated equivalent capability • knowledge and skills o strong understanding of  applications systems and networks are managed and secured o strong understanding  security threats and vulnerabilities attack vectors and adversary tactics techniques and procedures ttps o strong understanding of cyber forensic and ediscovery procedures to collect handle examine and analyze evidentiary artifacts while preserving integrity and maintaining a strict chain of custody o strong understanding of osi model o familiar with dfir tool sets eg encase ftk sleuth kit o proficient in some of the following tools metasploit nuix plaso powergrep relativity security onion sift workstation splunk tanium volatility wireshark yara o working knowledge in some of the following system design network architecture devsecops coordinated education and experience preferred o graduate degree in a technically rigorous domain such as computer science information security engineering etc o minimum  years of professional experience as a digital forensic investigator incident responder andor enterprise network security operations o previous experience in a fusion center andor exposure to large scale incident response o prior success leading forensic investigations andor managing individual contributors o prior experience with information technology andor information security in the financial services industry o prior experience with adversary emulation red teaming blue teaming o prior experience with one or more siems eg arcsight logrythm alienvault o prior experience with penetration testing of cloud environments eg aws gcp azure and devops technologies eg docker kubernetes jenkins git knowledge and skills o any professional certifications issued by giac aws etc o working knowledge  security models defenseindepth standards nist  cis  controls and frameworks mitre attack cyber kill chain stix o working knowledge of reverse engineering vulnerability discoveryanalysis andor exploit development o proficient in any query language eg sql o proficient in some of the following python ruby c c powershell o working knowledge of assembly or low level languages eg c o working knowledge of  such as switches routers firewalls in both windowslinux environments o working knowledge of virtualization products eg vmware workstation o working knowledge of security andor incident response in cloud environments o working knowledge of software development best practices including agile methods o familiar with atlassian tools you should be all of the following  a  success will depend on your ability to   establish clear narratives to describe investigative findings and working theories  clearly and concisely articulate any  that arise from investigative activities  motivate colleagues and partners to cooperate and support as needed  exert influence both verbally and in writing  a skilled and creative analyst success will depend on your ability to  stay current with the evolving landscape of threat activities and cybersecurity best practices  quickly synthesize information from disparate sources  understand organizations thoroughly to build relationships and establish trust  establish defensible working theories to explain observations and findings  think in terms of systems and controls  a goal oriented individual contributor success will depend on your ability to  stay motivated and work independently with minimal oversight  adapt to changing requirements in a fast paced environment  multitask and meet deadlines  priorities  navigate operational impediments in order  time sensitive tasks  identify and document any opportunities for process improvement  a reliable team player success will depend on your ability to  practice mutual respect at all times  establish trust and build strong partnerships  resolve conflict in a constructive manner and use as an opportunity to develop team unity  prioritize collective success ahead of individual ambition this job description provides a highlevel review of the types of work performed other jobrelated duties may be assigned as required must have flexibility to work outside of normal business hours when necessary  grade all job level  all job functionsall job level  all job functions  us  time type   citi is an equal opportunity and affirmative action employer minorityfemaleveteranindividuals with disabilitiessexual orientationgender identity citigroup inc and its subsidiaries citi invite all qualified interested applicants to apply for career opportunities if you are a person with a disability and need a reasonable  to use our search tools andor apply for a career opportunity click here  to view the eeo is the law poster click here  to view the eeo is the law supplement click here  to view the eeo policy statement click here  to view the pay transparency posting click here \n",
      "ENDDDDD/n\n",
      "<class 'str'>\n",
      "acts as a liaison among stakeholders performs analysis in order to understand the business needs policies and operations of the credit union and  solutions that support and enable the credit union to achieve its goals works on projects of varying magnitude and helps to ensure the implementation from beginning to end is timely and satisfactory to stakeholders completes any other job related duties needed to help drive to our vision fulfill our purpose and abide by our organizations valuesbachelor degree in management information systems mis computer science or businessrelated field  education andor experience minimum of five  years in a large financial institution environment  experience minimum of two  years of related experience andor training as a business analyst performing the following activities a requirements gathering b use case generation and documentation c design  solutions using multiple architectures d generation and documentation of both functional and technical design documents for use by self and other programming staff minimum of one  year handson experience designing and implementing technical solutions use of structured application development methodology and principals understanding of structured environments using distinct development test and production work in a team environment meet deadlines and take on a high level of responsibility and accountability environments superb critical thinking analytical interpersonal written and  skills excellent organizational skills with the ability to pay close attention to detailsexperience with fidelity information systems systematics banking software product suite proven experience in participatingcoordinating multiple simultaneous projects and ability to work with general supervision excellent knowledge of microsoft office suite word excel powerpoint and visiosecurity service federal credit union is an industry leader who has built a reputation of innovation strength and stability we pride ourselves on discovering and developing employees who have exceptional character and a genuine passion for helping others in return we deliver  total rewards package that supports the financial physical and emotional wellbeing of our employeesall employees should demonstrate our ssfcu core values  caring innovative honest fair and dedicated  while providing enthusiastic professional and courteous service to ssfcu members and employeesssfcu offers  total rewards package that  salary customizable benefit options paid time off  match with immediate vesting tuition reimbursement onsite fitness center or free gym membership and an awardwinning total wellbeing program focusing on the physical financial and emotional wellbeing of our employees we invest in  through our volunteer corps and in you through ongoing growth and development opportunities\n",
      "ENDDDDD/n\n",
      "<class 'str'>\n",
      "about you\n",
      "\n",
      "are you an expert in application integration data management and business intelligence and looking for a new challenge do you enjoy wearing many hats and working with different teams in an organization if the answer is “yes” then we have an exciting longterm opportunity for you who are we we are arco the designbuild experts\n",
      "\n",
      "we are looking for an experienced systems integration and data analyst who can join the technology team in our clayton office successful candidates will have expert knowledge in data architecture implementation experience with integration technologies and database experience\n",
      "\n",
      "what we can offer you\n",
      "\n",
      "we are dedicated to the wellbeing of our associates and are proud to be consistently recognized as a best place to work  and benefits package not only supports our associates and their families but benefits   around the world\n",
      "industryleading performancebased bonus program\n",
      "generously funded profit sharing\n",
      "traditional and roth \n",
      "tuition reimbursement for associates\n",
      "scholarship for associates’ children up to  per child\n",
      " paid sabbatical after every five years of employment plus  for travel\n",
      " paid volunteer leave each year\n",
      " charitable match\n",
      "medical dental and vision insurance coverage\n",
      " paid  maternity leave\n",
      "at arco our first core value is to treat people fairly and do the right thing we are proud to be an equal opportunity employer and all qualified applicants will receive consideration for employment\n",
      "\n",
      "a day in the life\n",
      "member of a growing technical team delivering technology supporting application integration business process simplification mdm and data analytics\n",
      "design develop deploy and support integration processes between applications across cloud andor on premise cloud services application and datawarehouse integration enterprise web services apis etl processes as the service expands this may grow to include data capture from iot devices and external data services\n",
      "design develop and deploy data analytics solutions leveraging data from enterprise applications developed solutions – both cloud and onpremise including erp crm hr\n",
      "opportunity to also be involved in application architecture and development efforts\n",
      "the team will be responsible for creating and maintaining formal data structures and data architecture this can include data models data definitions data flow diagrams data dictionaries and security  data access models\n",
      "provide business analyst teams with technical subject matter expertise and work with team other technicians and analysts to ensure development activities are aligned with scope schedule priority and business objectives\n",
      "responsible for establishing best practices in services development integration of applications and govern detailed designs generated by the vendors\n",
      "monitors and reports on progress  engagements and  goals\n",
      "necessary qualifications\n",
      "bachelors degree in technology related subject\n",
      " years of relevant it industry experience\n",
      "expert knowledge in data architecture modeling integration governance\n",
      "experience providing endtoend integration solutions development for enterprise software including hosted and saas hightech services\n",
      " years’ design and implementation experience with integration technologies eg informatica kafka boomi mulesoft\n",
      "database experience with ms sql oracle nosql databases is required\n",
      "strong knowledge of enterprise analytics big data platforms data exchange models mdm and cloud integration is preferred\n",
      "java or other classed basedobjectoriented programming languages\n",
      "make your move\n",
      "\n",
      "we are one of the fastestgrowing privately  in  over  designbuild projects across  states we ranked  out of the top   in the us and  on the enr top  contractors list of  most importantly our clients like us they trust us and want to do business with us we are looking for people with the same enthusiasm passion and respect for hard work that brought us to where we are today are you a person that can make a difference at arco if the answer is “yes” we look forward to meeting you\n",
      "\n",
      "arco does not accept unsolicited resumes from individual recruiters or thirdparty recruiting agencies without preapproval from arco’s human resource team preapproval is required before any external candidate can be submitted arco will not be responsible for fees related to unsolicited resumes and for candidates who are sent directly to our hiring managers\n",
      "ENDDDDD/n\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for item in dataset.head(20):\n",
    "    print(item)\n",
    "    print('ENDDDDD/n')\n",
    "    print(type(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only accepting English words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only accepting english words\n",
    "words = set(nltk.corpus.words.words())\n",
    "english_dataset = []\n",
    "def english_words(text):\n",
    "    text_clean = \" \".join(w for w in nltk.wordpunct_tokenize(text) \\\n",
    "         if w.lower() in words or not w.isalpha())\n",
    "    return text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only accepting english words\n",
    "clean_dataset = [english_words(description) for description in dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting our data list to a series\n",
    "series = pd.Series((i for i in clean_dataset)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stop words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stop words\n",
    "data = series.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize with POS Tag\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(word,get_wordnet_pos(word)) for word in tokenizer.tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean = [lemmatize_text(item) for item in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['financial',\n",
       " 'analyst',\n",
       " 'phoenix',\n",
       " 'banner',\n",
       " 'health',\n",
       " 'please',\n",
       " 'enable',\n",
       " 'continue',\n",
       " 'please',\n",
       " 'enable',\n",
       " 'browser',\n",
       " 'experience',\n",
       " 'site',\n",
       " 'ability',\n",
       " 'apply',\n",
       " 'job',\n",
       " 'page',\n",
       " 'candidate',\n",
       " 'log',\n",
       " 'back',\n",
       " 'financial',\n",
       " 'analyst',\n",
       " 'job',\n",
       " 'number',\n",
       " 'facility',\n",
       " 'corporate',\n",
       " 'office',\n",
       " 'department',\n",
       " 'security',\n",
       " 'address',\n",
       " 'street',\n",
       " 'north',\n",
       " 'central',\n",
       " 'ave',\n",
       " 'address',\n",
       " 'location',\n",
       " 'work',\n",
       " 'schedule',\n",
       " 'day',\n",
       " 'position',\n",
       " 'type',\n",
       " 'post',\n",
       " 'category',\n",
       " 'information',\n",
       " 'technology',\n",
       " 'nonclinical',\n",
       " 'health',\n",
       " 'care',\n",
       " 'constantly',\n",
       " 'banner',\n",
       " 'health',\n",
       " 'front',\n",
       " 'change',\n",
       " 'lead',\n",
       " 'health',\n",
       " 'care',\n",
       " 'make',\n",
       " 'experience',\n",
       " 'best',\n",
       " 'want',\n",
       " 'change',\n",
       " 'care',\n",
       " '–',\n",
       " 'people',\n",
       " 'choose',\n",
       " 'take',\n",
       " 'challenge',\n",
       " 'health',\n",
       " 'care',\n",
       " 'well',\n",
       " 'like',\n",
       " 'something',\n",
       " 'want',\n",
       " 'part',\n",
       " 'want',\n",
       " 'hear',\n",
       " 'business',\n",
       " 'analyst',\n",
       " 'organization',\n",
       " 'execute',\n",
       " 'management',\n",
       " 'financial',\n",
       " 'performance',\n",
       " 'conduct',\n",
       " 'deliver',\n",
       " 'financial',\n",
       " 'return',\n",
       " 'investment',\n",
       " 'cost',\n",
       " 'benefit',\n",
       " 'analysis',\n",
       " 'related',\n",
       " 'vendor',\n",
       " 'project',\n",
       " 'partner',\n",
       " 'across',\n",
       " 'leadership',\n",
       " 'team',\n",
       " 'drive',\n",
       " 'delivery',\n",
       " 'ensure',\n",
       " 'operational',\n",
       " 'investment',\n",
       " 'receive',\n",
       " 'spend',\n",
       " 'closely',\n",
       " 'plan',\n",
       " 'position',\n",
       " 'reside',\n",
       " 'banner',\n",
       " 'corporate',\n",
       " 'headquarters',\n",
       " 'phoenix',\n",
       " 'report',\n",
       " 'senior',\n",
       " 'director',\n",
       " 'strategic',\n",
       " 'delivery',\n",
       " 'pay',\n",
       " 'total',\n",
       " 'journey',\n",
       " 'banner',\n",
       " 'health',\n",
       " 'banner',\n",
       " 'health',\n",
       " 'variety',\n",
       " 'benefit',\n",
       " 'help',\n",
       " 'family',\n",
       " 'provide',\n",
       " 'health',\n",
       " 'financial',\n",
       " 'security',\n",
       " 'focus',\n",
       " 'best',\n",
       " 'enjoy',\n",
       " 'life',\n",
       " 'banner',\n",
       " 'health',\n",
       " 'corporate',\n",
       " 'within',\n",
       " 'banner',\n",
       " 'health',\n",
       " 'corporate',\n",
       " 'opportunity',\n",
       " 'apply',\n",
       " 'unique',\n",
       " 'experience',\n",
       " 'support',\n",
       " 'leader',\n",
       " 'offer',\n",
       " 'reward',\n",
       " 'wide',\n",
       " 'array',\n",
       " 'whether',\n",
       " 'background',\n",
       " 'human',\n",
       " 'finance',\n",
       " 'information',\n",
       " 'technology',\n",
       " 'legal',\n",
       " 'care',\n",
       " 'public',\n",
       " 'find',\n",
       " 'many',\n",
       " 'patient',\n",
       " 'care',\n",
       " 'banner',\n",
       " 'health',\n",
       " 'banner',\n",
       " 'health',\n",
       " 'one',\n",
       " 'nonprofit',\n",
       " 'health',\n",
       " 'care',\n",
       " 'country',\n",
       " 'lead',\n",
       " 'nonprofit',\n",
       " 'provider',\n",
       " 'hospital',\n",
       " 'serve',\n",
       " 'throughout',\n",
       " 'network',\n",
       " 'primary',\n",
       " 'care',\n",
       " 'health',\n",
       " 'research',\n",
       " 'physician',\n",
       " 'skilled',\n",
       " 'use',\n",
       " 'late',\n",
       " 'technology',\n",
       " 'make',\n",
       " 'health',\n",
       " 'care',\n",
       " 'easy',\n",
       " 'life',\n",
       " 'well',\n",
       " 'many',\n",
       " 'career',\n",
       " 'banner',\n",
       " 'health',\n",
       " 'help',\n",
       " 'make',\n",
       " 'banner',\n",
       " 'journey',\n",
       " 'unique',\n",
       " 'every',\n",
       " 'employee',\n",
       " 'job',\n",
       " 'summary',\n",
       " 'position',\n",
       " 'strategic',\n",
       " 'contributor',\n",
       " 'business',\n",
       " 'tactical',\n",
       " 'execution',\n",
       " 'business',\n",
       " 'integration',\n",
       " 'digital',\n",
       " 'inclusive',\n",
       " 'limited',\n",
       " 'web',\n",
       " 'site',\n",
       " 'development',\n",
       " 'mobile',\n",
       " 'platform',\n",
       " 'presence',\n",
       " 'internal',\n",
       " 'application',\n",
       " 'development',\n",
       " 'content',\n",
       " 'management',\n",
       " 'adoption',\n",
       " 'ongoing',\n",
       " 'maintenance',\n",
       " 'electronic',\n",
       " 'provide',\n",
       " 'knowledge',\n",
       " 'guidance',\n",
       " 'research',\n",
       " 'fact',\n",
       " 'find',\n",
       " 'define',\n",
       " 'design',\n",
       " 'modify',\n",
       " 'information',\n",
       " 'position',\n",
       " 'responsible',\n",
       " 'system',\n",
       " 'scope',\n",
       " 'relative',\n",
       " 'well',\n",
       " 'system',\n",
       " 'documentation',\n",
       " 'quality',\n",
       " 'assurance',\n",
       " 'essential',\n",
       " 'establish',\n",
       " 'manage',\n",
       " 'effective',\n",
       " 'dashboard',\n",
       " 'metric',\n",
       " 'progress',\n",
       " 'towards',\n",
       " 'specific',\n",
       " 'significant',\n",
       " 'role',\n",
       " 'creation',\n",
       " 'strategic',\n",
       " 'technology',\n",
       " 'review',\n",
       " 'consult',\n",
       " 'design',\n",
       " 'content',\n",
       " 'digital',\n",
       " 'ensure',\n",
       " 'consistency',\n",
       " 'across',\n",
       " 'electronic',\n",
       " 'efficiency',\n",
       " 'lack',\n",
       " 'redundancy',\n",
       " 'appropriateness',\n",
       " 'statistical',\n",
       " 'analysis',\n",
       " 'relevance',\n",
       " 'business',\n",
       " 'strategic',\n",
       " 'business',\n",
       " 'effective',\n",
       " 'use',\n",
       " 'electronic',\n",
       " 'channel',\n",
       " 'perspective',\n",
       " 'provide',\n",
       " 'leadership',\n",
       " 'mentorship',\n",
       " 'team',\n",
       " 'strategy',\n",
       " 'external',\n",
       " 'research',\n",
       " 'analysis',\n",
       " 'business',\n",
       " 'analysis',\n",
       " 'ultimately',\n",
       " 'implementation',\n",
       " 'electronic',\n",
       " 'high',\n",
       " 'level',\n",
       " 'guidance',\n",
       " 'junior',\n",
       " 'department',\n",
       " 'may',\n",
       " 'lead',\n",
       " 'plan',\n",
       " 'implement',\n",
       " 'facility',\n",
       " 'maximize',\n",
       " 'information',\n",
       " 'technology',\n",
       " 'service',\n",
       " 'quality',\n",
       " 'effectiveness',\n",
       " 'efficiency',\n",
       " 'business',\n",
       " 'effective',\n",
       " 'use',\n",
       " 'electronic',\n",
       " 'channel',\n",
       " 'perspective',\n",
       " 'leadership',\n",
       " 'staff',\n",
       " 'information',\n",
       " 'technology',\n",
       " 'staff',\n",
       " 'design',\n",
       " 'implementation',\n",
       " 'maintenance',\n",
       " 'application',\n",
       " 'system',\n",
       " 'team',\n",
       " 'information',\n",
       " 'technology',\n",
       " 'end',\n",
       " 'user',\n",
       " 'assemble',\n",
       " 'request',\n",
       " 'return',\n",
       " 'investment',\n",
       " 'roi',\n",
       " 'capital',\n",
       " 'operating',\n",
       " 'data',\n",
       " 'high',\n",
       " 'level',\n",
       " 'strategic',\n",
       " 'regard',\n",
       " 'application',\n",
       " 'end',\n",
       " 'user',\n",
       " 'customer',\n",
       " 'documentation',\n",
       " 'department',\n",
       " 'consistently',\n",
       " 'current',\n",
       " 'professional',\n",
       " 'technical',\n",
       " 'knowledge',\n",
       " 'industry',\n",
       " 'educational',\n",
       " 'personal',\n",
       " 'relevant',\n",
       " 'certification',\n",
       " 'licensure',\n",
       " 'business',\n",
       " 'need',\n",
       " 'require',\n",
       " 'minimum',\n",
       " 'must',\n",
       " 'posse',\n",
       " 'strong',\n",
       " 'technical',\n",
       " 'business',\n",
       " 'knowledge',\n",
       " 'typically',\n",
       " 'degree',\n",
       " 'related',\n",
       " 'field',\n",
       " 'must',\n",
       " 'also',\n",
       " 'knowledge',\n",
       " 'information',\n",
       " 'technology',\n",
       " 'specifically',\n",
       " 'design',\n",
       " 'large',\n",
       " 'consumer',\n",
       " 'within',\n",
       " 'job',\n",
       " 'function',\n",
       " 'would',\n",
       " 'normally',\n",
       " 'work',\n",
       " 'experience',\n",
       " 'demonstrate',\n",
       " 'expert',\n",
       " 'knowledge',\n",
       " 'information',\n",
       " 'technology',\n",
       " 'need',\n",
       " 'experience',\n",
       " 'medium',\n",
       " 'scale',\n",
       " 'project',\n",
       " 'either',\n",
       " 'individual',\n",
       " 'team',\n",
       " 'presentation',\n",
       " 'engage',\n",
       " 'technical',\n",
       " 'nontechnical',\n",
       " 'ability',\n",
       " 'interact',\n",
       " 'across',\n",
       " 'various',\n",
       " 'incumbent',\n",
       " 'mentor',\n",
       " 'less',\n",
       " 'experienced',\n",
       " 'team',\n",
       " 'typical',\n",
       " 'industry',\n",
       " 'variable',\n",
       " 'pager',\n",
       " 'may',\n",
       " 'prefer',\n",
       " 'additional',\n",
       " 'related',\n",
       " 'education',\n",
       " 'experience',\n",
       " 'prefer',\n",
       " 'additional',\n",
       " 'related',\n",
       " 'education',\n",
       " 'experience',\n",
       " 'prefer',\n",
       " 'apply',\n",
       " 'connect',\n",
       " 'u',\n",
       " 'join',\n",
       " 'one',\n",
       " 'talent',\n",
       " 'learn',\n",
       " 'career',\n",
       " 'banner',\n",
       " 'health']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_clean[5986]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting our data list to a series\n",
    "series_clean = pd.Series(i for i in dataset_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_clean_str = [str(item) for item in series_clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = series_clean.apply(lambda x:' '.join([stemmer.stem(str(word)) for word in x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing TF-IDF vs BOW method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               TF-IDF\n",
      "maintenance  0.360153\n",
      "marine       0.326817\n",
      "inspector    0.262237\n",
      "engineer     0.216660\n",
      "quality      0.205927\n",
      "equipment    0.190849\n",
      "corp         0.181680\n",
      "readiness    0.174221\n",
      "display      0.167905\n",
      "recovery     0.160400\n"
     ]
    }
   ],
   "source": [
    "tfIdfVectorizer=TfidfVectorizer(use_idf=True)\n",
    "tfIdf = tfIdfVectorizer.fit_transform(series_clean_str)\n",
    "df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "print (df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our dataset is large, we've used Latent Diricht Allocation for Dimension Reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training our model, we need to preprocess our input in order to get the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acceptable\n",
      "1 achieve\n",
      "2 allow\n",
      "3 along\n",
      "4 among\n",
      "5 analyze\n",
      "6 assign\n",
      "7 augmentation\n",
      "8 base\n",
      "9 class\n",
      "10 close\n"
     ]
    }
   ],
   "source": [
    "#creating a dictionary with number of occurrence\n",
    "dictionary = gensim.corpora.Dictionary(series_clean)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering our dictionary\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.5, keep_n=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1),\n",
       " (5, 1),\n",
       " (8, 1),\n",
       " (16, 2),\n",
       " (17, 1),\n",
       " (18, 1),\n",
       " (31, 2),\n",
       " (38, 1),\n",
       " (46, 1),\n",
       " (49, 1),\n",
       " (52, 1),\n",
       " (54, 2),\n",
       " (60, 1),\n",
       " (62, 1),\n",
       " (65, 2),\n",
       " (71, 1),\n",
       " (78, 1),\n",
       " (81, 1),\n",
       " (86, 1),\n",
       " (97, 1),\n",
       " (101, 2),\n",
       " (102, 1),\n",
       " (103, 1),\n",
       " (114, 1),\n",
       " (120, 2),\n",
       " (121, 1),\n",
       " (126, 1),\n",
       " (127, 1),\n",
       " (130, 3),\n",
       " (132, 1),\n",
       " (134, 1),\n",
       " (135, 2),\n",
       " (138, 1),\n",
       " (141, 3),\n",
       " (151, 2),\n",
       " (157, 1),\n",
       " (163, 2),\n",
       " (169, 1),\n",
       " (174, 1),\n",
       " (178, 1),\n",
       " (185, 1),\n",
       " (190, 1),\n",
       " (205, 1),\n",
       " (229, 1),\n",
       " (238, 3),\n",
       " (240, 1),\n",
       " (243, 1),\n",
       " (246, 5),\n",
       " (256, 2),\n",
       " (281, 1),\n",
       " (282, 1),\n",
       " (288, 1),\n",
       " (291, 1),\n",
       " (334, 1),\n",
       " (340, 1),\n",
       " (347, 1),\n",
       " (354, 1),\n",
       " (356, 2),\n",
       " (358, 6),\n",
       " (361, 1),\n",
       " (381, 1),\n",
       " (390, 4),\n",
       " (391, 25),\n",
       " (396, 2),\n",
       " (410, 7),\n",
       " (417, 2),\n",
       " (428, 1),\n",
       " (431, 1),\n",
       " (451, 1),\n",
       " (455, 1),\n",
       " (456, 1),\n",
       " (492, 1),\n",
       " (509, 1),\n",
       " (516, 1),\n",
       " (519, 3),\n",
       " (531, 1),\n",
       " (534, 2),\n",
       " (538, 1),\n",
       " (546, 2),\n",
       " (548, 1),\n",
       " (570, 2),\n",
       " (574, 1),\n",
       " (609, 5),\n",
       " (610, 2),\n",
       " (613, 1),\n",
       " (616, 1),\n",
       " (620, 1),\n",
       " (636, 1),\n",
       " (637, 1),\n",
       " (649, 1),\n",
       " (655, 1),\n",
       " (656, 1),\n",
       " (665, 1),\n",
       " (666, 1),\n",
       " (678, 3),\n",
       " (685, 1),\n",
       " (689, 1),\n",
       " (695, 1),\n",
       " (704, 1),\n",
       " (717, 1),\n",
       " (719, 1),\n",
       " (721, 1),\n",
       " (733, 1),\n",
       " (739, 1),\n",
       " (770, 1),\n",
       " (775, 2),\n",
       " (799, 2),\n",
       " (871, 1),\n",
       " (888, 1),\n",
       " (926, 1),\n",
       " (928, 1),\n",
       " (935, 1),\n",
       " (950, 1),\n",
       " (959, 1),\n",
       " (986, 1),\n",
       " (998, 1),\n",
       " (1015, 1),\n",
       " (1031, 1),\n",
       " (1077, 1),\n",
       " (1118, 3),\n",
       " (1127, 1),\n",
       " (1167, 1),\n",
       " (1187, 1),\n",
       " (1189, 1),\n",
       " (1205, 1),\n",
       " (1218, 1),\n",
       " (1292, 1),\n",
       " (1299, 1),\n",
       " (1303, 1),\n",
       " (1317, 1),\n",
       " (1327, 1),\n",
       " (1467, 1),\n",
       " (1486, 2),\n",
       " (1533, 1),\n",
       " (1596, 1),\n",
       " (1597, 1),\n",
       " (1628, 1),\n",
       " (1732, 1),\n",
       " (1736, 1),\n",
       " (1738, 1),\n",
       " (1788, 1),\n",
       " (1820, 1),\n",
       " (1891, 2),\n",
       " (1897, 3),\n",
       " (2032, 1),\n",
       " (2145, 1),\n",
       " (2169, 1),\n",
       " (2210, 1),\n",
       " (2567, 1),\n",
       " (2653, 1),\n",
       " (2758, 1),\n",
       " (2805, 1),\n",
       " (2848, 1),\n",
       " (2970, 1),\n",
       " (3364, 1),\n",
       " (3822, 1),\n",
       " (3971, 1),\n",
       " (4394, 1),\n",
       " (4637, 1)]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying out BOW method\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in series_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.06826236158097014),\n",
      " (1, 0.03712634345322998),\n",
      " (2, 0.057239571519254885),\n",
      " (3, 0.04346292678071762),\n",
      " (4, 0.052509443150834396),\n",
      " (5, 0.04128664015110409),\n",
      " (6, 0.05381386680255456),\n",
      " (7, 0.09710355509425028),\n",
      " (8, 0.03851779394637199),\n",
      " (9, 0.04568430857023668),\n",
      " (10, 0.04898439901857154),\n",
      " (11, 0.044395261174912964),\n",
      " (12, 0.05447986249082435),\n",
      " (13, 0.03395920881618943),\n",
      " (14, 0.10160160542957915),\n",
      " (15, 0.14899163356971953),\n",
      " (16, 0.03924776337523569),\n",
      " (17, 0.03946637979916749),\n",
      " (18, 0.03877345378047814),\n",
      " (19, 0.13515551220058386),\n",
      " (20, 0.08419529780523445),\n",
      " (21, 0.028609887898771526),\n",
      " (22, 0.08170166343394092),\n",
      " (23, 0.1507964224704855),\n",
      " (24, 0.02246435610289257),\n",
      " (25, 0.017807422846473252),\n",
      " (26, 0.14152658320422706),\n",
      " (27, 0.03395920881618943),\n",
      " (28, 0.13304909846409),\n",
      " (29, 0.03797592678912748),\n",
      " (30, 0.049883061061237396),\n",
      " (31, 0.05830731765694331),\n",
      " (32, 0.023847145599947973),\n",
      " (33, 0.028975920966831745),\n",
      " (34, 0.04979296914237805),\n",
      " (35, 0.23066321346095153),\n",
      " (36, 0.031330317556436525),\n",
      " (37, 0.08274280844962478),\n",
      " (38, 0.10254962643440473),\n",
      " (39, 0.07508120868032808),\n",
      " (40, 0.03499618379582552),\n",
      " (41, 0.03314163517975282),\n",
      " (42, 0.04151019878407484),\n",
      " (43, 0.024055348709014365),\n",
      " (44, 0.12222971969341594),\n",
      " (45, 0.2448447734337215),\n",
      " (46, 0.03426033398131192),\n",
      " (47, 0.2781716052632558),\n",
      " (48, 0.05832185922003112),\n",
      " (49, 0.03352290447717136),\n",
      " (50, 0.037699105617621374),\n",
      " (51, 0.07631785270112583),\n",
      " (52, 0.038778759094004474),\n",
      " (53, 0.04209610962566269),\n",
      " (54, 0.013208691353677707),\n",
      " (55, 0.039692526538400365),\n",
      " (56, 0.05406568091608939),\n",
      " (57, 0.05395847198121977),\n",
      " (58, 0.051536488226407454),\n",
      " (59, 0.04443858205493921),\n",
      " (60, 0.10684453707883952),\n",
      " (61, 0.14149851582483827),\n",
      " (62, 0.053945644854470134),\n",
      " (63, 0.08334424522887753),\n",
      " (64, 0.12762271132350403),\n",
      " (65, 0.023550936541153793),\n",
      " (66, 0.08025645711857168),\n",
      " (67, 0.09873686172009292),\n",
      " (68, 0.03732230164964649),\n",
      " (69, 0.11227111634648806),\n",
      " (70, 0.026426406280131716),\n",
      " (71, 0.024766646609198858),\n",
      " (72, 0.03730409867177589),\n",
      " (73, 0.036881849633348486),\n",
      " (74, 0.06275361626324644),\n",
      " (75, 0.01156878186738144),\n",
      " (76, 0.038691442429695896),\n",
      " (77, 0.05278212768452294),\n",
      " (78, 0.03420183089935614),\n",
      " (79, 0.04334067736264945),\n",
      " (80, 0.016070333737589412),\n",
      " (81, 0.022613076654756824),\n",
      " (82, 0.049378889849998574),\n",
      " (83, 0.6684279000743244)]\n"
     ]
    }
   ],
   "source": [
    "#trying out tfidf\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing our LDA model\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=5, id2word=dictionary, passes=15, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW Vectorized LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.013*\"position\" + 0.011*\"health\" + 0.009*\"may\" + 0.009*\"must\" + 0.007*\"research\" + 0.007*\"education\" + 0.007*\"related\" + 0.006*\"please\" + 0.006*\"time\" + 0.006*\"prefer\"\n",
      "Topic: 1 \n",
      "Words: 0.017*\"financial\" + 0.008*\"process\" + 0.008*\"status\" + 0.007*\"’\" + 0.007*\"risk\" + 0.006*\"finance\" + 0.006*\"project\" + 0.006*\"accounting\" + 0.006*\"related\" + 0.005*\"ensure\"\n",
      "Topic: 2 \n",
      "Words: 0.019*\"test\" + 0.019*\"project\" + 0.018*\"design\" + 0.017*\"technical\" + 0.012*\"·\" + 0.011*\"understand\" + 0.009*\"technology\" + 0.009*\"system\" + 0.009*\"process\" + 0.009*\"application\"\n",
      "Topic: 3 \n",
      "Words: 0.099*\"•\" + 0.028*\"security\" + 0.016*\"network\" + 0.012*\"technical\" + 0.010*\"system\" + 0.009*\"must\" + 0.008*\"engineering\" + 0.008*\"service\" + 0.007*\"infrastructure\" + 0.006*\"level\"\n",
      "Topic: 4 \n",
      "Words: 0.010*\"’\" + 0.009*\"analytics\" + 0.008*\"learn\" + 0.008*\"help\" + 0.007*\"u\" + 0.007*\"new\" + 0.007*\"opportunity\" + 0.006*\"people\" + 0.006*\"make\" + 0.006*\"product\"\n"
     ]
    }
   ],
   "source": [
    "#seeing our Topics\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.06826236158097014),\n",
      " (1, 0.03712634345322998),\n",
      " (2, 0.057239571519254885),\n",
      " (3, 0.04346292678071762),\n",
      " (4, 0.052509443150834396),\n",
      " (5, 0.04128664015110409),\n",
      " (6, 0.05381386680255456),\n",
      " (7, 0.09710355509425028),\n",
      " (8, 0.03851779394637199),\n",
      " (9, 0.04568430857023668),\n",
      " (10, 0.04898439901857154),\n",
      " (11, 0.044395261174912964),\n",
      " (12, 0.05447986249082435),\n",
      " (13, 0.03395920881618943),\n",
      " (14, 0.10160160542957915),\n",
      " (15, 0.14899163356971953),\n",
      " (16, 0.03924776337523569),\n",
      " (17, 0.03946637979916749),\n",
      " (18, 0.03877345378047814),\n",
      " (19, 0.13515551220058386),\n",
      " (20, 0.08419529780523445),\n",
      " (21, 0.028609887898771526),\n",
      " (22, 0.08170166343394092),\n",
      " (23, 0.1507964224704855),\n",
      " (24, 0.02246435610289257),\n",
      " (25, 0.017807422846473252),\n",
      " (26, 0.14152658320422706),\n",
      " (27, 0.03395920881618943),\n",
      " (28, 0.13304909846409),\n",
      " (29, 0.03797592678912748),\n",
      " (30, 0.049883061061237396),\n",
      " (31, 0.05830731765694331),\n",
      " (32, 0.023847145599947973),\n",
      " (33, 0.028975920966831745),\n",
      " (34, 0.04979296914237805),\n",
      " (35, 0.23066321346095153),\n",
      " (36, 0.031330317556436525),\n",
      " (37, 0.08274280844962478),\n",
      " (38, 0.10254962643440473),\n",
      " (39, 0.07508120868032808),\n",
      " (40, 0.03499618379582552),\n",
      " (41, 0.03314163517975282),\n",
      " (42, 0.04151019878407484),\n",
      " (43, 0.024055348709014365),\n",
      " (44, 0.12222971969341594),\n",
      " (45, 0.2448447734337215),\n",
      " (46, 0.03426033398131192),\n",
      " (47, 0.2781716052632558),\n",
      " (48, 0.05832185922003112),\n",
      " (49, 0.03352290447717136),\n",
      " (50, 0.037699105617621374),\n",
      " (51, 0.07631785270112583),\n",
      " (52, 0.038778759094004474),\n",
      " (53, 0.04209610962566269),\n",
      " (54, 0.013208691353677707),\n",
      " (55, 0.039692526538400365),\n",
      " (56, 0.05406568091608939),\n",
      " (57, 0.05395847198121977),\n",
      " (58, 0.051536488226407454),\n",
      " (59, 0.04443858205493921),\n",
      " (60, 0.10684453707883952),\n",
      " (61, 0.14149851582483827),\n",
      " (62, 0.053945644854470134),\n",
      " (63, 0.08334424522887753),\n",
      " (64, 0.12762271132350403),\n",
      " (65, 0.023550936541153793),\n",
      " (66, 0.08025645711857168),\n",
      " (67, 0.09873686172009292),\n",
      " (68, 0.03732230164964649),\n",
      " (69, 0.11227111634648806),\n",
      " (70, 0.026426406280131716),\n",
      " (71, 0.024766646609198858),\n",
      " (72, 0.03730409867177589),\n",
      " (73, 0.036881849633348486),\n",
      " (74, 0.06275361626324644),\n",
      " (75, 0.01156878186738144),\n",
      " (76, 0.038691442429695896),\n",
      " (77, 0.05278212768452294),\n",
      " (78, 0.03420183089935614),\n",
      " (79, 0.04334067736264945),\n",
      " (80, 0.016070333737589412),\n",
      " (81, 0.022613076654756824),\n",
      " (82, 0.049378889849998574),\n",
      " (83, 0.6684279000743244)]\n"
     ]
    }
   ],
   "source": [
    "#Using bow_corpus to use TFIDF \n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Vectorized LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.023*\"•\" + 0.006*\"project\" + 0.005*\"test\" + 0.004*\"system\" + 0.004*\"sap\" + 0.004*\"functional\" + 0.003*\"user\" + 0.003*\"technical\" + 0.003*\"client\" + 0.003*\"process\"\n",
      "Topic: 1 Word: 0.014*\"web\" + 0.012*\"developer\" + 0.008*\"c\" + 0.007*\"code\" + 0.007*\"test\" + 0.007*\"server\" + 0.006*\"design\" + 0.006*\"application\" + 0.006*\"oracle\" + 0.006*\"net\"\n",
      "Topic: 2 Word: 0.026*\"·\" + 0.014*\"security\" + 0.011*\"network\" + 0.007*\"cisco\" + 0.006*\"hardware\" + 0.005*\"•\" + 0.005*\"clearance\" + 0.004*\"government\" + 0.004*\"infrastructure\" + 0.004*\"system\"\n",
      "Topic: 3 Word: 0.011*\"spark\" + 0.010*\"cloud\" + 0.009*\"big\" + 0.009*\"python\" + 0.008*\"tech\" + 0.008*\"locate\" + 0.008*\"engineer\" + 0.008*\"statistical\" + 0.008*\"hive\" + 0.007*\"azure\"\n",
      "Topic: 4 Word: 0.003*\"’\" + 0.003*\"analytics\" + 0.003*\"health\" + 0.003*\"marketing\" + 0.002*\"status\" + 0.002*\"learn\" + 0.002*\"financial\" + 0.002*\"research\" + 0.002*\"people\" + 0.002*\"product\"\n"
     ]
    }
   ],
   "source": [
    "#Training our model with TFIDF vectors\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=5, id2word=dictionary, passes=15, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW method seems to work better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess for unseen documents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_vector(document):\n",
    "    bow_vector = dictionary.doc2bow(preprocess(document))\n",
    "    return bow_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV1 = 'Structured cross border Funds, worked with consultants on preparation and review of Fund structures and documentation/ setting up of entities/ obtaining tax exemptions (13X/13R).'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV2 = 'Reporting to Managing Partner, the FC role is responsible for financial control and all accounting activities as well as tax reporting of the Master-Feeder Fund and its 10  SPVs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV3 = 'Machine Learning Engineer, worked with nlp and computer vison'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vector1 = dictionary.doc2bow(preprocess(CV1))\n",
    "bow_vector2 = dictionary.doc2bow(preprocess(CV2))\n",
    "bow_vector3 = dictionary.doc2bow(preprocess(CV3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing and vectorizing the unseen document i norder to get results\n",
    "bow_vector = dictionary.doc2bow(preprocess(CV2))\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, topic in lda_model.print_topics(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparing each CV to a certain job description, we're using Cosine Similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = 'Tetra Tech is seeking mid to senior level Silverlight Developer to support a highly visible federal government contract, particularly focused around supporting the mission of transportation. The candidate is responsible for working with business requirements and develop application using Silverlight. The candidate should be a self-starter, motivated, able to manage multiple priorities and tasks in a dynamic environment with a good understanding of software development standards and best practices.  Primary job duties and responsibilities may include, but are not limited to the following: This position will design and develop solutions using Silverlight to meet requirements provided by the customer.This position could feasibly work with XAML, JavaScript, Web Services, python scripting and RDBMS technologies such as SQL Server during a given release cycle.Work closely with project managers, partner companies, and customers to analyze complex problems, define requirements and implement solutions.The successful candidate will have:Requirements:7+ years of IT experience with at least 3 years in Silverlight developmentExcellent analytical and problem-solving skillsFamiliarity with basic User Interface and User Experience principlesUnderstanding of Web Services and Open-Standard Data SpecificationsMicrosoft Development Stack (C#, XAML, ASP.Net, JavaScript)Experience with ESRI’s Web API (Silverlight)Database programming experience with SQL ServerExperience working in a dynamic, Agile development environment Ability to prioritize, plan and estimate interdependent tasksAbility to operate independently as needed to implement assignmentsAbility to effectively communicate design concepts and architecture to customers and stakeholdersDesired Skills/Experience:Experience developing and integrating with Geospatial Map and Web ServicesExperience developing and integrating with Geospatial Processing TasksExperience developing with Python within ESRI’s ArcGIS Technology StackDeveloping WCF Services (SOAP, REST)Experience with ArcGIS Server data management operationsExperience developing on non-ESRI geospatial platforms (Google, Bing Maps, open source tools)Experience using FME Tetra Tech is an Equal Opportunity Employer, and we value workplace diversity. We invite resumes from all interested parties and consider applicants for all positions without regard to race, color, religion, sex, national origin, age, marital status, sexual preference, personal appearance, family responsibility, the presence of a non-job-related medical condition or physical disability, matriculation, political affiliation, veteran status, or any other legally protected status. Tetra Tech is a VEVRAA federal contractor and we request priority referral of veterans for available positions.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetorized_job_description = dictionary.doc2bow(preprocess(job_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_list = sorted[(cosine_similarity(CV1,job_description)),(cosine_similarity(CV2,job_description),(cosine_similarity(CV3,job_description)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV3 is the best fit for this job description with 63.8 similarity\n"
     ]
    }
   ],
   "source": [
    "print('{} is the best fit for this job description with {} similarity'.format(CV,cosine_similarity_list[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This unsupervised algorithem can catagorize CVs and Job Descriptions using Topic Modeling, and detect the most related CV to a job description, as well as finding the best fit amongst a group of CVs for a certain job description using cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Possible Updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li> As you've observed, we have 5 categories of job description which mostly consist of health technician, developement,business and finance related jobs. for further update, we can add more categories such as law, art, data science, etc. </li>\n",
    "    <li> Pipeline feature where you can compare multiple CVs together.</li>\n",
    "    <li> We can add a skill extraction feature which detects specific skills in a CV</li>\n",
    "    <li> We can add a PDF reader feature, which would have the ability to compare PDF CVs as wel. </li>\n",
    "    <li> Ranking CVs based on seniority and education level. </li>\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
